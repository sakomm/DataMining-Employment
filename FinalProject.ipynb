{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of Layoffs in the United States Tech Industry \n",
    "\n",
    "## Project Motivation and Background\n",
    "\n",
    "As Computer Science students about to enter the job market, we're concerned about the volatility of the tech industry. We want to analyze and create a system that can help people understand the markets, plan an exit strategy, and alleviate these concerns.\n",
    "\n",
    "## Project Goal:\n",
    "The goal of our project is to analyze trends in companies' recent layoffs in a variety of industries (aerospace, travel, retail, etc.) and detect patterns and trends.  This will be done by looking at the number of employees laid off, the location of the companies, their stages, and the funds they have raised.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>total_laid_off</th>\n",
       "      <th>percentage_laid_off</th>\n",
       "      <th>date</th>\n",
       "      <th>stage</th>\n",
       "      <th>country</th>\n",
       "      <th>funds_raised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N26</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Finance</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Series E</td>\n",
       "      <td>United States</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Providoor</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dropbox</td>\n",
       "      <td>SF Bay Area</td>\n",
       "      <td>Other</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>Post-IPO</td>\n",
       "      <td>United States</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vroom</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>Post-IPO</td>\n",
       "      <td>United States</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenhouse</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>United States</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company       location        industry  total_laid_off  \\\n",
       "0         N26         Berlin         Finance            71.0   \n",
       "1   Providoor      Melbourne            Food             NaN   \n",
       "2     Dropbox    SF Bay Area           Other           500.0   \n",
       "3       Vroom  New York City  Transportation           120.0   \n",
       "4  Greenhouse  New York City      Recruiting           100.0   \n",
       "\n",
       "   percentage_laid_off        date           stage        country  \\\n",
       "0                 0.04  2023-04-28        Series E  United States   \n",
       "1                 1.00  2023-04-28         Unknown      Australia   \n",
       "2                 0.16  2023-04-27        Post-IPO  United States   \n",
       "3                 0.11  2023-04-27        Post-IPO  United States   \n",
       "4                 0.12  2023-04-27  Private Equity  United States   \n",
       "\n",
       "   funds_raised  \n",
       "0        1700.0  \n",
       "1           NaN  \n",
       "2        1700.0  \n",
       "3        1300.0  \n",
       "4         110.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "layoffs = pd.read_csv('layoffs.csv')\n",
    "layoffs.head()\n",
    "print(layoffs.columns)\n",
    "#we have to drop all rows with a blank percentage layed off cell\n",
    "layoffs.dropna(subset=['percentage_laid_off'], inplace=True)\n",
    "\n",
    "# one hot encoding for categorical variables \n",
    "print(f\"Unique values for 'company': {len(layoffs['company'].unique())}\")\n",
    "\n",
    "# Adding dummy variables for location, industry, stage, and country\n",
    "totalNewCols = len(layoffs['location'].unique()) + len(layoffs['industry'].unique()) + len(layoffs['stage'].unique()) + len(layoffs['country'].unique())\n",
    "print(f\"Total number of new columns: {totalNewCols}\")\n",
    "\n",
    "#loca = pd.get_dummies(layoffs['location'], prefix='location')\n",
    "indu = pd.get_dummies(layoffs['industry'], prefix='industry')\n",
    "stag = pd.get_dummies(layoffs['stage'], prefix='stage')\n",
    "#coun = pd.get_dummies(layoffs['country'], prefix='country')\n",
    "\n",
    "# drop the original columns\n",
    "layoffs.drop(['location', 'industry', 'stage', 'country'], axis=1, inplace=True)\n",
    "\n",
    "# concat the new columns\n",
    "#layoffs = pd.concat([layoffs, loca, indu, stag, coun], axis=1)\n",
    "layoffs = pd.concat([layoffs, indu, stag], axis=1)\n",
    "layoffs = layoffs[layoffs.stage_Unknown != 1]\n",
    "layoffs = layoffs[layoffs.industry_Other != 1]\n",
    "\n",
    "\n",
    "layoffs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1074, 48)\n",
      "Testing set shape: (268, 48)\n"
     ]
    }
   ],
   "source": [
    "traing_data = layoffs.drop(['company', 'date'], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_set = traing_data.sample(frac=0.8, random_state=0)\n",
    "test_set = traing_data.drop(train_set.index)\n",
    "\n",
    "print (f\"Training set shape: {train_set.shape}\")\n",
    "print (f\"Testing set shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ridge_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import arange\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# print(f'train cols: {train_set.columns}')\n",
    "# establish training set\n",
    "#values for our training set\n",
    "X_train = train_set.drop(['percentage_laid_off', 'total_laid_off'], axis=1)\n",
    "\n",
    "#fill in blank cells\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "#labels for our training set\n",
    "y_train = train_set[\"percentage_laid_off\"]\n",
    "\n",
    "#define cross-validation method to evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#define model\n",
    "model = RidgeCV(alphas=arange(0.001, 1.0, 0.001), cv=cv)\n",
    "#put values and labels into a csv file to look at\n",
    "X_train.to_csv('training_X.csv', index=False)\n",
    "y_train.to_csv('training_Y.csv', index=False)\n",
    "\n",
    "#fit model (this line is what takes so long to run)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R ** 2 score: 0.30480895857786716\n",
      "variance: 0.3071394706300371\n",
      "mse: 0.040260498458100404\n",
      "mae: 0.14663207695160835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the lambda that produced the lowest test MSE\n",
    "\n",
    "\n",
    "#code to do validation with our test set\n",
    "X_test = test_set.drop(['percentage_laid_off', 'total_laid_off'], axis=1)\n",
    "X_test = X_test.fillna(0)\n",
    "X_train_test = scaler.transform(X_test)\n",
    "\n",
    "y_test = test_set[\"percentage_laid_off\"]\n",
    "y_predict = model.predict(X_train_test)\n",
    "\n",
    "X_test.to_csv('test_X.csv',index=False)\n",
    "y_test.to_csv('test_Y.csv',index=False)\n",
    "\n",
    "y_predict_df = pd.DataFrame(y_predict, columns=['percentage_laid_off'])\n",
    "score = r2_score(y_test, y_predict)\n",
    "print(f'R ** 2 score: {score}')\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "var = explained_variance_score(y_test, y_predict)\n",
    "print(f'variance: {var}')   \n",
    "\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print(f'mse: {mse}')\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_predict)\n",
    "print(f'mae: {mae}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions compared to actual:\n",
      "    percentage_laid_off  percentage_laid_off\n",
      "0              0.385498                 0.40\n",
      "1              0.247519                 0.25\n",
      "2              0.240291                 0.20\n",
      "3              0.394545                 0.17\n",
      "4              0.649684                 1.00\n",
      "5              0.161085                 0.40\n",
      "6              0.263073                 0.10\n",
      "7              0.240121                 0.20\n",
      "8              0.317366                 0.20\n",
      "9              0.247451                 0.45\n",
      "10             0.187187                 0.16\n",
      "11             0.118454                 0.02\n",
      "12             0.171499                 0.25\n",
      "13             0.155730                 0.20\n",
      "14             0.227644                 0.14\n",
      "15             0.218486                 0.08\n",
      "16             0.095426                 0.03\n",
      "17             0.478469                 0.11\n",
      "18             0.092234                 0.08\n",
      "19             0.244628                 0.14\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions compared to actual:\")\n",
    "print(pd.concat([y_predict_df.head(20), y_test.reset_index(drop=True).head(20)], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.25194299552906135\n",
      "Standard Deviation: 0.24712653922661773\n",
      "Median: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14232/3315180513.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['risk'] = 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14232/3315180513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percentage_laid_off'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.17\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'risk'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percentage_laid_off'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Giving a label classifier to the percentage laid off\n",
    "\n",
    "# Statistacl analysis of the data find the mean and standard deviation\n",
    "mean = layoffs['percentage_laid_off'].mean()\n",
    "std = layoffs['percentage_laid_off'].std()\n",
    "median = layoffs['percentage_laid_off'].median()\n",
    "\n",
    "print (f\"Mean: {mean}\")\n",
    "print (f\"Standard Deviation: {std}\")\n",
    "print (f\"Median: {median}\")\n",
    "\n",
    "# Given median and standard deviation, we can classify the percentage laid off into 3 categories\n",
    "\n",
    "# Mean: 0.25194299552906113\n",
    "# Standard Deviation: 0.24712653922661823\n",
    "# Median: 0.17\n",
    "\n",
    "# 0.00 - 0.17 = 0 # Lower Risk\n",
    "# 0.17 - 0.25 = 1 # Medium Risk\n",
    "# 0.25 - 0.37 = 2 # High Risk\n",
    "# 0.37 - *    = 3 # Very High Risk\n",
    "\n",
    "# Create a new column for the label\n",
    "y_predict_df['risk'] = 0\n",
    "y_test['risk'] = 0\n",
    "\n",
    "\n",
    "# Iterate through the rows and assign the label\n",
    "for index, row in y_predict_df.iterrows():\n",
    "    if row['percentage_laid_off'] < 0.17:\n",
    "        y_predict_df.at[index, 'risk'] = 0\n",
    "    elif row['percentage_laid_off'] < 0.25:\n",
    "        y_predict_df.at[index, 'risk'] = 1\n",
    "    elif row['percentage_laid_off'] < 0.37:\n",
    "        y_predict_df.at[index, 'risk'] = 2\n",
    "    else:\n",
    "        y_predict_df.at[index, 'risk'] = 3\n",
    "\n",
    "for index, row in y_test.iteritems():\n",
    "    if row['percentage_laid_off'] < 0.17:\n",
    "        y_test.at[index, 'risk'] = 0\n",
    "    elif row['percentage_laid_off'] < 0.25:\n",
    "        y_test.at[index, 'risk'] = 1\n",
    "    elif row['percentage_laid_off'] < 0.37:\n",
    "        y_test.at[index, 'risk'] = 2\n",
    "    else:\n",
    "        y_test.at[index, 'risk'] = 3\n",
    "\n",
    "r2 = r2_score(y_test['risk'], y_predict_df['risk'])\n",
    "print(f'R ** 2 score: {r2}')\n",
    "\n",
    "\n",
    "# compare the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R ** 2 score: -2.7053853375437398\n",
      "Predictions compared to actual:\n",
      "    percentage_laid_off  risk  risk\n",
      "0              1.601971   3.0     3\n",
      "1              0.951865   3.0     2\n",
      "2              1.053346   3.0     1\n",
      "3              1.802433   3.0     1\n",
      "4              2.525088   3.0     3\n",
      "5              0.581978   3.0     3\n",
      "6              1.030918   3.0     0\n",
      "7              1.052504   3.0     1\n",
      "8              1.505438   3.0     1\n",
      "9              0.953494   3.0     3\n",
      "10             0.615540   3.0     0\n",
      "11             0.068217   0.0     0\n",
      "12             0.642373   3.0     2\n",
      "13             0.692333   3.0     1\n",
      "14             0.872703   3.0     0\n",
      "15             0.727664   3.0     0\n",
      "16             0.237083   1.0     0\n",
      "17             2.189183   3.0     0\n",
      "18             0.234215   1.0     0\n",
      "19             1.132783   3.0     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
