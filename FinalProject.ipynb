{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of Layoffs in the United States Tech Industry \n",
    "\n",
    "## Project Motivation and Background\n",
    "\n",
    "As Computer Science students about to enter the job market, we're concerned about the volatility of the tech industry. We want to analyze and create a system that can help people understand the markets, plan an exit strategy, and alleviate these concerns.\n",
    "\n",
    "## Project Goal:\n",
    "The goal of our project is to analyze trends in companies' recent layoffs in a variety of industries (aerospace, travel, retail, etc.) and detect patterns and trends.  This will be done by looking at the number of employees laid off, the location of the companies, their stages, and the funds they have raised.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['company', 'location', 'industry', 'total_laid_off',\n",
      "       'percentage_laid_off', 'date', 'stage', 'country', 'funds_raised'],\n",
      "      dtype='object')\n",
      "Unique values for 'company': 1438\n",
      "Total number of new columns: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>total_laid_off</th>\n",
       "      <th>percentage_laid_off</th>\n",
       "      <th>date</th>\n",
       "      <th>funds_raised</th>\n",
       "      <th>industry_Aerospace</th>\n",
       "      <th>industry_Construction</th>\n",
       "      <th>industry_Consumer</th>\n",
       "      <th>industry_Crypto</th>\n",
       "      <th>industry_Data</th>\n",
       "      <th>...</th>\n",
       "      <th>stage_Series C</th>\n",
       "      <th>stage_Series D</th>\n",
       "      <th>stage_Series E</th>\n",
       "      <th>stage_Series F</th>\n",
       "      <th>stage_Series G</th>\n",
       "      <th>stage_Series H</th>\n",
       "      <th>stage_Series I</th>\n",
       "      <th>stage_Series J</th>\n",
       "      <th>stage_Subsidiary</th>\n",
       "      <th>stage_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N26</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vroom</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenhouse</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Megaport</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airtasker</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company  total_laid_off  percentage_laid_off        date  funds_raised  \\\n",
       "0         N26            71.0                 0.04  2023-04-28        1700.0   \n",
       "3       Vroom           120.0                 0.11  2023-04-27        1300.0   \n",
       "4  Greenhouse           100.0                 0.12  2023-04-27         110.0   \n",
       "7    Megaport            50.0                 0.16  2023-04-27          98.0   \n",
       "8   Airtasker            45.0                 0.20  2023-04-27          26.0   \n",
       "\n",
       "   industry_Aerospace  industry_Construction  industry_Consumer  \\\n",
       "0                   0                      0                  0   \n",
       "3                   0                      0                  0   \n",
       "4                   0                      0                  0   \n",
       "7                   0                      0                  0   \n",
       "8                   0                      0                  0   \n",
       "\n",
       "   industry_Crypto  industry_Data  ...  stage_Series C  stage_Series D  \\\n",
       "0                0              0  ...               0               0   \n",
       "3                0              0  ...               0               0   \n",
       "4                0              0  ...               0               0   \n",
       "7                0              0  ...               0               0   \n",
       "8                0              0  ...               1               0   \n",
       "\n",
       "   stage_Series E  stage_Series F  stage_Series G  stage_Series H  \\\n",
       "0               1               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "7               0               0               0               0   \n",
       "8               0               0               0               0   \n",
       "\n",
       "   stage_Series I  stage_Series J  stage_Subsidiary  stage_Unknown  \n",
       "0               0               0                 0              0  \n",
       "3               0               0                 0              0  \n",
       "4               0               0                 0              0  \n",
       "7               0               0                 0              0  \n",
       "8               0               0                 0              0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "layoffs = pd.read_csv('layoffs.csv')\n",
    "layoffs.head()\n",
    "print(layoffs.columns)\n",
    "#we have to drop all rows with a blank percentage layed off cell\n",
    "layoffs.dropna(subset=['percentage_laid_off'], inplace=True)\n",
    "\n",
    "# one hot encoding for categorical variables \n",
    "print(f\"Unique values for 'company': {len(layoffs['company'].unique())}\")\n",
    "\n",
    "# Adding dummy variables for location, industry, stage, and country\n",
    "totalNewCols = len(layoffs['location'].unique()) + len(layoffs['industry'].unique()) + len(layoffs['stage'].unique()) + len(layoffs['country'].unique())\n",
    "print(f\"Total number of new columns: {totalNewCols}\")\n",
    "\n",
    "#loca = pd.get_dummies(layoffs['location'], prefix='location')\n",
    "indu = pd.get_dummies(layoffs['industry'], prefix='industry')\n",
    "stag = pd.get_dummies(layoffs['stage'], prefix='stage')\n",
    "#coun = pd.get_dummies(layoffs['country'], prefix='country')\n",
    "\n",
    "# drop the original columns\n",
    "layoffs.drop(['location', 'industry', 'stage', 'country'], axis=1, inplace=True)\n",
    "\n",
    "# concat the new columns\n",
    "#layoffs = pd.concat([layoffs, loca, indu, stag, coun], axis=1)\n",
    "layoffs = pd.concat([layoffs, indu, stag], axis=1)\n",
    "layoffs = layoffs[layoffs.stage_Unknown != 1]\n",
    "layoffs = layoffs[layoffs.industry_Other != 1]\n",
    "\n",
    "\n",
    "layoffs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1074, 48)\n",
      "Testing set shape: (268, 48)\n"
     ]
    }
   ],
   "source": [
    "traing_data = layoffs.drop(['company', 'date'], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_set = traing_data.sample(frac=0.8, random_state=0)\n",
    "test_set = traing_data.drop(train_set.index)\n",
    "\n",
    "print (f\"Training set shape: {train_set.shape}\")\n",
    "print (f\"Testing set shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ridge_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import arange\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# print(f'train cols: {train_set.columns}')\n",
    "# establish training set\n",
    "#values for our training set\n",
    "X_train = train_set.drop(['percentage_laid_off', 'total_laid_off'], axis=1)\n",
    "\n",
    "#fill in blank cells\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "#labels for our training set\n",
    "y_train = train_set[\"percentage_laid_off\"]\n",
    "\n",
    "#define cross-validation method to evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#define model\n",
    "model = RidgeCV(alphas=arange(0.001, 1.0, 0.001), cv=cv)\n",
    "#put values and labels into a csv file to look at\n",
    "X_train.to_csv('training_X.csv', index=False)\n",
    "y_train.to_csv('training_Y.csv', index=False)\n",
    "\n",
    "#fit model (this line is what takes so long to run)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R ** 2 score: 0.30480895857786616\n",
      "variance: 0.3071394706300361\n",
      "mse: 0.04026049845810046\n",
      "mae: 0.14663207695160854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the lambda that produced the lowest test MSE\n",
    "\n",
    "\n",
    "#code to do validation with our test set\n",
    "X_test = test_set.drop(['percentage_laid_off', 'total_laid_off'], axis=1)\n",
    "X_test = X_test.fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_train_test = scaler.fit_transform(X_test)\n",
    "\n",
    "y_test = test_set[\"percentage_laid_off\"]\n",
    "y_predict = model.predict(X_train_test)\n",
    "\n",
    "X_test.to_csv('test_X.csv',index=False)\n",
    "y_test.to_csv('test_Y.csv',index=False)\n",
    "\n",
    "y_predict_df = pd.DataFrame(y_predict, columns=['percentage_laid_off'])\n",
    "score = r2_score(y_test, y_predict)\n",
    "print(f'R ** 2 score: {score}')\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "var = explained_variance_score(y_test, y_predict)\n",
    "print(f'variance: {var}')   \n",
    "\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print(f'mse: {mse}')\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_predict)\n",
    "print(f'mae: {mae}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions compared to actual:\n",
      "    percentage_laid_off  percentage_laid_off\n",
      "0              0.385498                 0.40\n",
      "1              0.247519                 0.25\n",
      "2              0.240291                 0.20\n",
      "3              0.394545                 0.17\n",
      "4              0.649684                 1.00\n",
      "5              0.161085                 0.40\n",
      "6              0.263073                 0.10\n",
      "7              0.240121                 0.20\n",
      "8              0.317366                 0.20\n",
      "9              0.247451                 0.45\n",
      "10             0.187187                 0.16\n",
      "11             0.118454                 0.02\n",
      "12             0.171499                 0.25\n",
      "13             0.155730                 0.20\n",
      "14             0.227644                 0.14\n",
      "15             0.218486                 0.08\n",
      "16             0.095426                 0.03\n",
      "17             0.478469                 0.11\n",
      "18             0.092234                 0.08\n",
      "19             0.244628                 0.14\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions compared to actual:\")\n",
    "print(pd.concat([y_predict_df.head(20), y_test.reset_index(drop=True).head(20)], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.25194299552906113\n",
      "Standard Deviation: 0.24712653922661823\n",
      "Median: 0.17\n",
      "Training set shape: (1074, 49)\n",
      "Testing set shape: (268, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053, 0.054,\n",
       "       0.055, 0.0...\n",
       "       0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953, 0.954,\n",
       "       0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962, 0.963,\n",
       "       0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971, 0.972,\n",
       "       0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 , 0.981,\n",
       "       0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99 ,\n",
       "       0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Giving a label classifier to the percentage laid off\n",
    "\n",
    "# Statistacl analysis of the data find the mean and standard deviation\n",
    "mean = layoffs['percentage_laid_off'].mean()\n",
    "std = layoffs['percentage_laid_off'].std()\n",
    "median = layoffs['percentage_laid_off'].median()\n",
    "\n",
    "print (f\"Mean: {mean}\")\n",
    "print (f\"Standard Deviation: {std}\")\n",
    "print (f\"Median: {median}\")\n",
    "\n",
    "# Given median and standard deviation, we can classify the percentage laid off into 3 categories\n",
    "\n",
    "# Mean: 0.25194299552906113\n",
    "# Standard Deviation: 0.24712653922661823\n",
    "# Median: 0.17\n",
    "\n",
    "# 0.00 - 0.17 = 0 # Lower Risk\n",
    "# 0.17 - 0.25 = 1 # Medium Risk\n",
    "# 0.25 - 0.37 = 2 # High Risk\n",
    "# 0.37 - *    = 3 # Very High Risk\n",
    "\n",
    "# Create a new column for the label\n",
    "layoffs['risk'] = 0\n",
    "\n",
    "# Iterate through the rows and assign the label\n",
    "for index, row in layoffs.iterrows():\n",
    "    if row['percentage_laid_off'] < 0.17:\n",
    "        layoffs.at[index, 'risk'] = 0\n",
    "    elif row['percentage_laid_off'] < 0.25:\n",
    "        layoffs.at[index, 'risk'] = 1\n",
    "    elif row['percentage_laid_off'] < 0.37:\n",
    "        layoffs.at[index, 'risk'] = 2\n",
    "    else:\n",
    "        layoffs.at[index, 'risk'] = 3\n",
    "\n",
    "traing_data = layoffs.drop(['company', 'date'], axis=1)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_set = traing_data.sample(frac=0.8, random_state=0)\n",
    "test_set = traing_data.drop(train_set.index)\n",
    "\n",
    "print (f\"Training set shape: {train_set.shape}\")\n",
    "print (f\"Testing set shape: {test_set.shape}\")\n",
    "\n",
    "X_train = train_set.drop(['percentage_laid_off', 'risk'], axis=1)\n",
    "\n",
    "#fill in blank cells\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "#labels for our training set\n",
    "y_train = train_set[\"risk\"]\n",
    "\n",
    "#define cross-validation method to evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#define model\n",
    "model = RidgeCV(alphas=arange(0.001, 1.0, 0.001), cv=cv)\n",
    "#put values and labels into a csv file to look at\n",
    "X_train.to_csv('training_X.csv', index=False)\n",
    "y_train.to_csv('training_Y.csv', index=False)\n",
    "\n",
    "#fit model (this line is what takes so long to run)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2029592333398692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the risk\n",
    "X_test = test_set.drop(['percentage_laid_off', 'risk'], axis=1)\n",
    "X_test = X_test.fillna(0)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_test = scaler.fit_transform(X_test)\n",
    "\n",
    "y_test = test_set[\"risk\"]\n",
    "\n",
    "y_predict = model.predict(X_train_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
